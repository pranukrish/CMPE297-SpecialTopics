{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOecHhgHueki8/ATs01abQE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranukrish/CMPE297-SpecialTopics/blob/main/Assignment3/TextbooksAreAllYouNeed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqWbRZhFEg8o",
        "outputId": "cf66474e-bfd2-4754-830f-23e7a0dc6831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface_hub, transformers, accelerate\n",
            "Successfully installed accelerate-0.22.0 huggingface_hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"jinaai/starcoder-1b-textbook\", device_map='auto'\n",
        "    )\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"jinaai/starcoder-1b-textbook\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "ff21c1213b96433ea61a79a8ec66c42d",
            "884c8f11ed4d4f378ebd91e55c6246fd",
            "74f4baf6c31a4ffa8a8c95dd99e48e4c",
            "27c04cf7d7574be182f1073363b8df2e",
            "274d1f15d0794f74a6f6d73ef66f8f6c",
            "9205ee62a66c4429a0d2785309201417",
            "d4a429d52b0b462c9936859374681a2b",
            "41df7201b59f428b925302091e773b99",
            "57dfe8bbba30475787b35d87fdf52ff0",
            "5492262c8df04fce969f6c7f851df2a7",
            "e191ec75513e42ec84e2db45c18b8b8a",
            "c34f67eb5d17416aa5c80e42988beaa2",
            "c52ddc61e0784b7c8ed52cb68aeed8ec",
            "97c56744e47e4ccb83e83c59b8f18737",
            "48fe95a66f6748809c7f08d8221b90cb",
            "b5d503730e2b4a6590eac09f35d82afc",
            "11040f34534e4dab85edc9877b9d896b",
            "eb7db59f41cd4ef7b349e14dc27b2500",
            "0a52faf9f5854cd7b11f7991c13567a1",
            "bdfe3f863c5a462695c5bbbd0d8c32c1",
            "59d420a3e0e8465b9d39155397ee8ce6",
            "872be6523c394f98b9cd10f661da8820",
            "f402b9c4f8154665b07677b11df40128",
            "0314ff469f5d4bc899c20d12724d7dac",
            "6f58cccf1de144a7823fb87d61bdae0a",
            "96deadad650941c7959b425bff17f684",
            "7938dd7325f0479b8f81a5454cfe99ef",
            "1628bd8ec6c94966968a46b751d37c2d",
            "2e756182ca904781a909e3b560a1e5fa",
            "5d9eca6271d64c1287a763edaf257f79",
            "2e9f0a3015e84d47b3f72e6f32f1d4d2",
            "4629876a89cc4fa9b2abf90d842b6560",
            "6a38471412aa4e63b42dc67227232ff1",
            "828d3f5718db4711b1522f9aac67bd06",
            "90ecebf7b70c487ea1bcba653b4e65f7",
            "fbfb61fb3d0547d89c3941ea332edf0c",
            "97cf2e27dc33481f95323c3ec5f4cdbb",
            "dd712d17efa0444e9113497e190d9128",
            "9056879ca2b44f6c8c172f9b4cc8bc75",
            "98f23cdd70c7491ca4d6868ccf0b8085",
            "ccf87f5272004be2a978a81da6644d2d",
            "33c636bc09fe4edba9834295e8680b81",
            "01c9e9d81da04bd795e667eca365aae9",
            "8f66d2e6183141ee9811de47b7037727",
            "0afdd8e097b2458f8d10821aebb39d75",
            "2e24cf6996be429d9c775772bbdac50a",
            "ef43f45cc5d04d89ac1a8c55ae8e22c3",
            "36cf4125cbf649a3b067126059cceee0",
            "6a65986251f04df8b89c354960eab818",
            "f6c5a9c79ff0475190c5ec697d1746b0",
            "0e61b8452b3045c09d5e3b3f8c5193bb",
            "cc722a63646741598f5e01f0793411da",
            "96f9144c609c4cb884309ad0e8b6f40f",
            "78682d67f62545cbaa546c9f905f526c",
            "1926ca47cbc345f88c5a36b796bc8b15",
            "2df83f57665d48fbbf73c8fad0702994",
            "be3c590a24994b2185209fefa3eadf4e",
            "de2e4689a464404ab60caa73f7d06eb9",
            "7b228014af724eb18100bca8ee1c9892",
            "c6fd3c43f82d41d086065250953d0940",
            "b5fe2cbc00104155b4f26d224d4251ca",
            "2ae6424aa18146d99e3eafc85825a25e",
            "cc4f424cc9b3466b9a1fce5b6b087cc6",
            "432810ee2aba48a5baa4d03f097369a4",
            "7a1bbf839a16416fb05f8a48ceb656f4",
            "ae47f43919154af3b6d46c03a19f155e",
            "652ab3b2a6ca42b4ac6da4154a400ee2",
            "eabdbb19a68e4816942df36df0e75c5a",
            "a2d522182e004087afabb4dfbddc0e04",
            "d6dccfd89607492fbe74fa8ec08dd2ee",
            "396fda4b063d4ebf996d4b4645fe3367",
            "d7d2fc213a6e42bd9f1dff0a89829c99",
            "0055e3483ae9416483eb369d4f051972",
            "8a662087ac3b42f58d941d75c06a8838",
            "d59d9e286a2d4c77a631a6a1b161cbf4",
            "a04f407982b74d9693158792f609af8a",
            "619111ec0295470e97bce8f09df640a0",
            "49ef14cab87b449fb66eae1fafffa10f",
            "c276544c2ff74cf287e629ae0d534671",
            "7e53538335354785a749816c2d208030",
            "db237f46566e4c658a337deee291bba8",
            "85d9bf19009247ae84df1a3dce931ac4",
            "c7d259e213e64922842623c8de089e93",
            "955d85cbfc8144cfba44489a974e7fcf",
            "310db9ce98db4d0092994bf250841a46",
            "e10001b0d19441da8e3489097a2fec37",
            "f9bccd90fc4342529f78ec25dc41e7c4",
            "371ac0b31fa140c1be2565b9103ba357"
          ]
        },
        "id": "MzVDD03HE7NO",
        "outputId": "01d5ee0f-1edc-4f52-b556-f65b53e7d7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff21c1213b96433ea61a79a8ec66c42d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c34f67eb5d17416aa5c80e42988beaa2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f402b9c4f8154665b07677b11df40128"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/717 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "828d3f5718db4711b1522f9aac67bd06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/777k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0afdd8e097b2458f8d10821aebb39d75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/442k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2df83f57665d48fbbf73c8fad0702994"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.06M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "652ab3b2a6ca42b4ac6da4154a400ee2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49ef14cab87b449fb66eae1fafffa10f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "generate a python function that given a positive integer, it returns its roman numeral equivalent as a string,\n",
        "\n",
        "def int_to_mini_roman\n",
        "'''\n",
        "\n",
        "inputs = tokenizer(prompt.rstrip(), return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "generation_output = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=256,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    return_dict_in_generate=True,\n",
        ")\n",
        "\n",
        "s = generation_output.sequences[0]\n",
        "output = tokenizer.decode(s, skip_special_tokens=True)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L06S2RyuFZkX",
        "outputId": "45ba2e3a-da68-4100-cc74-16f8a7b1473c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generate a python function that given a positive integer, it returns its roman numeral equivalent as a string,\n",
            "\n",
            "def int_to_mini_roman(num):\n",
            "    roman_dict = {1000: 'M', 900: 'CM', 500: 'D', 400: 'CD', 100: 'C', 90: 'XC', 50: 'L', 40: 'XL', 10: 'X', 9: 'IX', 5: 'V', 4: 'IV', 1: 'I'}\n",
            "    roman_num = \"\"\n",
            "    for key, value in roman_dict.items():\n",
            "        while num >= key:\n",
            "            roman_num += value\n",
            "            num -= key\n",
            "    return roman_num\n",
            "\n",
            "\n",
            "# Example usage\n",
            "print(int_to_mini_roman(2000))  # Output: \"MXXI\"\n",
            "print(int_to_mini_roman(1500))  # Output: \"MXXX\"\n",
            "print(int_to_mini_roman(1000))  # Output: \"M\"\n",
            "print(int_to_mini_roman(500))  # Output: \"D\"\n",
            "print(int_to_mini_roman(1\n"
          ]
        }
      ]
    }
  ]
}